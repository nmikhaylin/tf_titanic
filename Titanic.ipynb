{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string(\"summaries_dir\", \"summaries\", \"Directory for summaries.\")\n",
    "flags.DEFINE_integer(\"num_iterations\", 10, \"Number of iteration cycles.\")\n",
    "flags.DEFINE_integer(\"num_updates_per_iteration\", 10, \"Number of weight updates per iteration.\")\n",
    "\n",
    "DATA_FOLDER = \"/media/nikita/BigData/projects/tf_projects/titanic/data\"\n",
    "\n",
    "\n",
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "\n",
    "def ExtractCabinLetter(cabin_str):\n",
    "  if cabin_str:\n",
    "    match = re.match(\"[a-zA-Z]+\", cabin_str)\n",
    "    if match:\n",
    "      return match.group(0)\n",
    "  return \"\"\n",
    "\n",
    "def ExtractCabinNumber(cabin_str):\n",
    "  if cabin_str:\n",
    "    match = re.search(\"[0-9]+\", cabin_str)\n",
    "    if match:\n",
    "      return int(match.group(0))\n",
    "  return -1\n",
    "\n",
    "\n",
    "def LoadTestingData():\n",
    "  raw_rows = []\n",
    "  pclasses = set()\n",
    "  genders = set()\n",
    "  embarked = set()\n",
    "  cabin_letters = set()\n",
    "  cabin_numbers = set()\n",
    "  df = pd.DataFrame(\n",
    "      columns=[\"PassengerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\",\n",
    "               \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin_Letter\", \"Cabin_Number\", \"Embarked\"])\n",
    "  with open(os.path.join(DATA_FOLDER, \"titanic_test.csv\"), \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "      raw_rows.append(row)\n",
    "      if not row[\"Embarked\"] in pclasses:\n",
    "          embarked.add(row[\"Embarked\"])\n",
    "      if not row[\"Sex\"] in pclasses:\n",
    "          genders.add(row[\"Sex\"])\n",
    "      if not row[\"Pclass\"] in pclasses:\n",
    "          pclasses.add(row[\"Pclass\"])\n",
    "      cabin_letter = ExtractCabinLetter(row[\"Cabin\"])\n",
    "      if not cabin_letter in cabin_letters:\n",
    "          cabin_letters.add(cabin_letter)\n",
    "      row[\"Cabin_Letter\"] = cabin_letter\n",
    "      cabin_number = ExtractCabinNumber(row[\"Cabin\"])\n",
    "      if not cabin_number in cabin_numbers:\n",
    "          cabin_numbers.add(cabin_number)\n",
    "      row[\"Cabin_Number\"] = cabin_number\n",
    "      row[\"Parch\"] = int(row[\"Parch\"])\n",
    "      row[\"Fare\"] = float(row[\"Parch\"])\n",
    "      del row[\"Cabin\"]\n",
    "      df.loc[row[\"PassengerId\"]] = pd.Series(row)\n",
    "  return df\n",
    "\n",
    "\n",
    "def LoadTrainingData():\n",
    "  raw_rows = []\n",
    "  pclasses = set()\n",
    "  genders = set()\n",
    "  embarked = set()\n",
    "  cabin_letters = set()\n",
    "  cabin_numbers = set()\n",
    "  df = pd.DataFrame(\n",
    "      columns=[\"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\",\n",
    "               \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin_Letter\", \"Cabin_Number\", \"Embarked\"])\n",
    "  with open(os.path.join(DATA_FOLDER, \"titanic_train.csv\"), \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "      raw_rows.append(row)\n",
    "      if not row[\"Embarked\"] in pclasses:\n",
    "          embarked.add(row[\"Embarked\"])\n",
    "      if not row[\"Sex\"] in pclasses:\n",
    "          genders.add(row[\"Sex\"])\n",
    "      if not row[\"Pclass\"] in pclasses:\n",
    "          pclasses.add(row[\"Pclass\"])\n",
    "      cabin_letter = ExtractCabinLetter(row[\"Cabin\"])\n",
    "      if not cabin_letter in cabin_letters:\n",
    "          cabin_letters.add(cabin_letter)\n",
    "      row[\"Cabin_Letter\"] = cabin_letter\n",
    "      cabin_number = ExtractCabinNumber(row[\"Cabin\"])\n",
    "      if not cabin_number in cabin_numbers:\n",
    "          cabin_numbers.add(cabin_number)\n",
    "      row[\"Cabin_Number\"] = cabin_number\n",
    "      row[\"Parch\"] = int(row[\"Parch\"])\n",
    "      row[\"Fare\"] = float(row[\"Parch\"])\n",
    "      del row[\"Cabin\"]\n",
    "      df.loc[row[\"PassengerId\"]] = pd.Series(row)\n",
    "  return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  training_df = LoadTrainingData()\n",
    "  testing_df = LoadTestingData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_df = training_df.drop(\"Survived\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MakePredictions(training_df, testing_df):\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    training_labels = training_df[\"Survived\"].astype(np.int32)\n",
    "    training_features = ProcessFeatures(training_df.drop(\"Survived\", 1))\n",
    "    print training_features\n",
    "    testing_features = ProcessFeatures(testing_df)\n",
    "    labels = training_labels.values\n",
    "    one_hotted_labels = pd.get_dummies(labels).as_matrix()\n",
    "    feature_size = training_features.shape[1]\n",
    "    print \"Number of features: %d\" % feature_size\n",
    "    input_features = tf.placeholder(tf.float32, shape=[None, feature_size])\n",
    "    output_labels = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "    # Output is survived or not.\n",
    "    W = tf.Variable(tf.zeros([feature_size, 2]))\n",
    "    b = tf.Variable(tf.zeros([2]))\n",
    "    pred = tf.nn.softmax(tf.matmul(input_features, W) + b)\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(pred, output_labels))\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    sess.run(initializer)\n",
    "    print \"Initial cost: %f\" % cost.eval(\n",
    "        feed_dict={input_features: training_features, output_labels: one_hotted_labels})\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(one_hotted_labels,1), tf.argmax(pred,1)), tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + \"/train\", sess.graph)\n",
    "    summary = sess.run(merged, feed_dict={input_features: training_features,\n",
    "                                    output_labels: one_hotted_labels})\n",
    "    train_writer.add_summary(summary)\n",
    "    print \"Initial Accuracy %f\" % accuracy.eval(\n",
    "        feed_dict={input_features: training_features, output_labels: one_hotted_labels})\n",
    "    train_step.run(\n",
    "        feed_dict={input_features: training_features, output_labels: one_hotted_labels})\n",
    "    print \"Final cost: %f\" % cost.eval(\n",
    "        feed_dict={input_features: training_features, output_labels: one_hotted_labels})\n",
    "    print \"Final Accuracy %f\" % accuracy.eval(\n",
    "        feed_dict={input_features: training_features, output_labels: one_hotted_labels})\n",
    "    print \"Predictions: \"\n",
    "    predictions = tf.argmax(pred, 1).eval(\n",
    "        feed_dict={input_features: testing_features})\n",
    "    print len(predictions)\n",
    "    ret_df = pd.DataFrame(data={\"PassengerId\": testing_df[\"PassengerId\"],\n",
    "                                \"Survived\": predictions})\n",
    "    print ret_df\n",
    "\n",
    "    return ret_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ProcessFeatures(raw_df):\n",
    "  \"\"\"Returns a dict for the fixed tensor columns.\"\"\"\n",
    "  ret_df = raw_df.drop(\"Name\", 1)\n",
    "  ret_df = ret_df.drop(\"Ticket\", 1)\n",
    "  ret_df = ret_df.drop(\"PassengerId\", 1)\n",
    "  remove_unknowns = lambda x:  float(x) if x else 30.0\n",
    "  is_unknown = lambda x:  False if x else True\n",
    "  ret_df[\"Age_Unknown\"] = ret_df[\"Age\"].apply(is_unknown)\n",
    "  ret_df[\"Age\"] = ret_df[\"Age\"].apply(remove_unknowns)\n",
    "  ret_df[\"Fare_Unknown\"] = ret_df[\"Fare\"].apply(is_unknown)\n",
    "  ret_df[\"Fare\"] = ret_df[\"Fare\"].apply(remove_unknowns)\n",
    "  int_columns = [\"Parch\", \"SibSp\"]\n",
    "  for column in int_columns:\n",
    "      ret_df[column] = ret_df[column].astype(np.int32)\n",
    "  categorical_columns = [\n",
    "      \"Pclass\", \"Sex\", \"Cabin_Letter\", \"Embarked\", \"Fare_Unknown\",\n",
    "      \"Age_Unknown\"]\n",
    "  one_hotted = pd.get_dummies(\n",
    "      ret_df, columns=categorical_columns).astype(np.float32)\n",
    "  for col in (set([u'Cabin_Letter_',\n",
    "                   u'Cabin_Letter_A', u'Cabin_Letter_B', u'Cabin_Letter_C',\n",
    "                   u'Cabin_Letter_D', u'Cabin_Letter_E', u'Cabin_Letter_F',\n",
    "                   u'Cabin_Letter_G', u'Embarked_C', u'Cabin_Letter_T', u'Embarked_',\n",
    "                   u'Embarked_Q', u'Embarked_S'])\n",
    "              - set(one_hotted.columns)):\n",
    "      one_hotted[col] = 0.0\n",
    "  print one_hotted.describe()\n",
    "  one_hotted = one_hotted[list(sorted(one_hotted.columns))]\n",
    "  # Remove unnecessary columns from the full matrix.\n",
    "  print one_hotted.columns\n",
    "  columns_to_select = [\"Sex_male\", \"Sex_female\", \"Age\", \"Age_Unknown_True\",\n",
    "                       \"Age_Unknown_False\", \"Fare\", \"Fare_Unknown_True\",\n",
    "                       \"Fare_Unknown_False\", \"Cabin_Number\", \"Pclass_1\",\n",
    "                       \"Pclass_2\", \"Pclass_3\"]\n",
    "  return one_hotted[columns_to_select].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age       SibSp       Parch        Fare  Cabin_Number  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000    891.000000   \n",
      "mean    29.758888    0.523008    0.381594   23.209877     10.557800   \n",
      "std     13.002570    1.102744    0.806057   12.128884     27.242765   \n",
      "min      0.420000    0.000000    0.000000    1.000000     -1.000000   \n",
      "25%     22.000000    0.000000    0.000000   30.000000     -1.000000   \n",
      "50%     30.000000    0.000000    0.000000   30.000000     -1.000000   \n",
      "75%     35.000000    1.000000    0.000000   30.000000     -1.000000   \n",
      "max     80.000000    8.000000    6.000000   30.000000    148.000000   \n",
      "\n",
      "         Pclass_1    Pclass_2    Pclass_3  Sex_female    Sex_male  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.242424    0.206510    0.551066    0.352413    0.647587   \n",
      "std      0.428790    0.405028    0.497665    0.477990    0.477990   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    1.000000    0.000000    1.000000   \n",
      "75%      0.000000    0.000000    1.000000    1.000000    1.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             ...         Cabin_Letter_G  Cabin_Letter_T   Embarked_  \\\n",
      "count        ...             891.000000      891.000000  891.000000   \n",
      "mean         ...               0.004489        0.001122    0.002245   \n",
      "std          ...               0.066889        0.033501    0.047351   \n",
      "min          ...               0.000000        0.000000    0.000000   \n",
      "25%          ...               0.000000        0.000000    0.000000   \n",
      "50%          ...               0.000000        0.000000    0.000000   \n",
      "75%          ...               0.000000        0.000000    0.000000   \n",
      "max          ...               1.000000        1.000000    1.000000   \n",
      "\n",
      "       Embarked_C  Embarked_Q  Embarked_S  Fare_Unknown_False  \\\n",
      "count  891.000000  891.000000  891.000000          891.000000   \n",
      "mean     0.188552    0.086420    0.722783            0.239057   \n",
      "std      0.391372    0.281141    0.447876            0.426747   \n",
      "min      0.000000    0.000000    0.000000            0.000000   \n",
      "25%      0.000000    0.000000    0.000000            0.000000   \n",
      "50%      0.000000    0.000000    1.000000            0.000000   \n",
      "75%      0.000000    0.000000    1.000000            0.000000   \n",
      "max      1.000000    1.000000    1.000000            1.000000   \n",
      "\n",
      "       Fare_Unknown_True  Age_Unknown_False  Age_Unknown_True  \n",
      "count         891.000000         891.000000        891.000000  \n",
      "mean            0.760943           0.801347          0.198653  \n",
      "std             0.426747           0.399210          0.399210  \n",
      "min             0.000000           0.000000          0.000000  \n",
      "25%             1.000000           1.000000          0.000000  \n",
      "50%             1.000000           1.000000          0.000000  \n",
      "75%             1.000000           1.000000          0.000000  \n",
      "max             1.000000           1.000000          1.000000  \n",
      "\n",
      "[8 rows x 27 columns]\n",
      "Index([u'Age', u'Age_Unknown_False', u'Age_Unknown_True', u'Cabin_Letter_',\n",
      "       u'Cabin_Letter_A', u'Cabin_Letter_B', u'Cabin_Letter_C',\n",
      "       u'Cabin_Letter_D', u'Cabin_Letter_E', u'Cabin_Letter_F',\n",
      "       u'Cabin_Letter_G', u'Cabin_Letter_T', u'Cabin_Number', u'Embarked_',\n",
      "       u'Embarked_C', u'Embarked_Q', u'Embarked_S', u'Fare',\n",
      "       u'Fare_Unknown_False', u'Fare_Unknown_True', u'Parch', u'Pclass_1',\n",
      "       u'Pclass_2', u'Pclass_3', u'Sex_female', u'Sex_male', u'SibSp'],\n",
      "      dtype='object')\n",
      "[[  1.   0.  22. ...,   0.   0.   1.]\n",
      " [  0.   1.  38. ...,   1.   0.   0.]\n",
      " [  0.   1.  26. ...,   0.   0.   1.]\n",
      " ..., \n",
      " [  0.   1.  30. ...,   0.   0.   1.]\n",
      " [  1.   0.  26. ...,   1.   0.   0.]\n",
      " [  1.   0.  32. ...,   0.   0.   1.]]\n",
      "              Age       SibSp       Parch        Fare  Cabin_Number  \\\n",
      "count  418.000000  418.000000  418.000000  418.000000    418.000000   \n",
      "mean    30.216507    0.447368    0.392345   23.645933      9.358851   \n",
      "std     12.635016    0.896760    0.981429   11.829079     24.450615   \n",
      "min      0.170000    0.000000    0.000000    1.000000     -1.000000   \n",
      "25%     23.000000    0.000000    0.000000   30.000000     -1.000000   \n",
      "50%     30.000000    0.000000    0.000000   30.000000     -1.000000   \n",
      "75%     35.750000    1.000000    0.000000   30.000000     -1.000000   \n",
      "max     76.000000    8.000000    9.000000   30.000000    132.000000   \n",
      "\n",
      "         Pclass_1    Pclass_2    Pclass_3  Sex_female    Sex_male    ...      \\\n",
      "count  418.000000  418.000000  418.000000  418.000000  418.000000    ...       \n",
      "mean     0.255981    0.222488    0.521531    0.363636    0.636364    ...       \n",
      "std      0.436934    0.416416    0.500135    0.481622    0.481622    ...       \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    ...       \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    ...       \n",
      "50%      0.000000    0.000000    1.000000    0.000000    1.000000    ...       \n",
      "75%      1.000000    0.000000    1.000000    1.000000    1.000000    ...       \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    ...       \n",
      "\n",
      "       Cabin_Letter_G  Embarked_C  Embarked_Q  Embarked_S  Fare_Unknown_False  \\\n",
      "count      418.000000  418.000000  418.000000  418.000000          418.000000   \n",
      "mean         0.002392    0.244019    0.110048    0.645933            0.224880   \n",
      "std          0.048912    0.430019    0.313324    0.478803            0.418004   \n",
      "min          0.000000    0.000000    0.000000    0.000000            0.000000   \n",
      "25%          0.000000    0.000000    0.000000    0.000000            0.000000   \n",
      "50%          0.000000    0.000000    0.000000    1.000000            0.000000   \n",
      "75%          0.000000    0.000000    0.000000    1.000000            0.000000   \n",
      "max          1.000000    1.000000    1.000000    1.000000            1.000000   \n",
      "\n",
      "       Fare_Unknown_True  Age_Unknown_False  Age_Unknown_True  Cabin_Letter_T  \\\n",
      "count         418.000000         418.000000        418.000000           418.0   \n",
      "mean            0.775120           0.794258          0.205742             0.0   \n",
      "std             0.418004           0.404727          0.404727             0.0   \n",
      "min             0.000000           0.000000          0.000000             0.0   \n",
      "25%             1.000000           1.000000          0.000000             0.0   \n",
      "50%             1.000000           1.000000          0.000000             0.0   \n",
      "75%             1.000000           1.000000          0.000000             0.0   \n",
      "max             1.000000           1.000000          1.000000             0.0   \n",
      "\n",
      "       Embarked_  \n",
      "count      418.0  \n",
      "mean         0.0  \n",
      "std          0.0  \n",
      "min          0.0  \n",
      "25%          0.0  \n",
      "50%          0.0  \n",
      "75%          0.0  \n",
      "max          0.0  \n",
      "\n",
      "[8 rows x 27 columns]\n",
      "Index([               u'Age',  u'Age_Unknown_False',   u'Age_Unknown_True',\n",
      "            u'Cabin_Letter_',     u'Cabin_Letter_A',     u'Cabin_Letter_B',\n",
      "           u'Cabin_Letter_C',     u'Cabin_Letter_D',     u'Cabin_Letter_E',\n",
      "           u'Cabin_Letter_F',     u'Cabin_Letter_G',     u'Cabin_Letter_T',\n",
      "             u'Cabin_Number',          u'Embarked_',         u'Embarked_C',\n",
      "               u'Embarked_Q',         u'Embarked_S',               u'Fare',\n",
      "       u'Fare_Unknown_False',  u'Fare_Unknown_True',              u'Parch',\n",
      "                 u'Pclass_1',           u'Pclass_2',           u'Pclass_3',\n",
      "               u'Sex_female',           u'Sex_male',              u'SibSp'],\n",
      "      dtype='object')\n",
      "<type 'numpy.ndarray'>\n",
      "(891, 1)\n",
      "float32\n",
      "Number of features: 12\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'Placeholder', defined at:\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-7745f87b6089>\", line 10, in <module>\n    input_features = tf.placeholder(tf.float32, shape=[None, feature_size])\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-298c8b2bb046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates_per_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       summary = sess.run(merged, feed_dict={input_features: training_features,\n\u001b[0;32m---> 30\u001b[0;31m                                       output_labels: float_labels})\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       update_weights.run(feed_dict={input_features: training_features,\n",
      "\u001b[0;32m/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'Placeholder', defined at:\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-7745f87b6089>\", line 10, in <module>\n    input_features = tf.placeholder(tf.float32, shape=[None, feature_size])\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/nikita/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "  with tf.Session() as sess:\n",
    "    training_labels = training_df[\"Survived\"].astype(np.float32)\n",
    "    training_features = ProcessFeatures(training_df.drop(\"Survived\", 1))\n",
    "    print training_features\n",
    "    testing_features = ProcessFeatures(testing_df)\n",
    "    float_labels = np.expand_dims(training_labels, axis=1)\n",
    "    print type(float_labels)\n",
    "    print float_labels.shape\n",
    "    print float_labels.dtype\n",
    "    feature_size = training_features.shape[1]\n",
    "    print \"Number of features: %d\" % feature_size\n",
    "    input_features = tf.placeholder(tf.float32, shape=[None, feature_size])\n",
    "    output_labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    # Output is survived or not.\n",
    "    W = tf.Variable(tf.zeros([feature_size, 1]))\n",
    "    b = tf.Variable(tf.zeros([1]))\n",
    "    y = tf.matmul(input_features, W) + b\n",
    "    add_delta = tf.matmul(tf.transpose(input_features), output_labels - y)\n",
    "    update_weights = W.assign_add(add_delta)\n",
    "    pred = tf.cast(tf.cast(y > 0, tf.bool), tf.float32)\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    sess.run(initializer)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, output_labels), tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + \"/train\", sess.graph)\n",
    "    for i in range(FLAGS.num_iterations):\n",
    "      for i in range(FLAGS.num_updates_per_iteration):\n",
    "        summary = sess.run(merged, feed_dict={input_features: training_features,\n",
    "                                        output_labels: float_labels})\n",
    "        train_writer.add_summary(summary)\n",
    "        update_weights.run(feed_dict={input_features: training_features,\n",
    "                                        output_labels: float_labels})\n",
    "    print \"Final accuracy: %f\" % accuracy.eval(\n",
    "        feed_dict={input_features: training_features,\n",
    "                   output_labels: one_hotted_labels})\n",
    "    ret_df = pd.DataFrame(data={\"PassengerId\": testing_df[\"PassengerId\"],\n",
    "                                \"Survived\": pred})\n",
    "    print ret_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
